# Awesome-DevAI [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

**DevAI is the community of developers building software with the help of [large language models (LLMs)](https://a16z.com/ai-canon).**

## Getting started

Many developers have concerns about how LLMs will impact development. [What AI won’t replace in your programming](https://www.infoworld.com/article/3709230/what-ai-wont-replace-in-your-programming.html) describes why the expertise and intuition of programmers will remain important.

It can be hard to figure out what LLM to use while coding. [What LLM to use? A perspective from the DevAI space](https://github.com/continuedev/what-llm-to-use) walks you through the most popular commercial and open-source models.

Researchers use benchmarks to evaluate and compare the relative performance of LLMs. [An introduction to code LLM benchmarks for software engineers](https://blog.continue.dev/an-introduction-to-code-llm-benchmarks-for-software-engineers/) gives you an overview of the current code benchmarks, so you can use them to figure out which LLMs are worth trying.

When you use an LLM while coding, you might want to adjust the preset. [Is it still necessary to tune an LLM preset? Tracing the history of temperature, penalty, and sampling schemes](https://blog.continue.dev/tune-llm-preset/) gives you the confidence to adjust the model preset when needed.

If you find an open-source code LLM useful, you will likely want to deploy it for your entire team. [How to deploy an open-source code LLM for your dev team](https://github.com/continuedev/deploy-os-code-llm) provides a guide on how to make this happen.

Codex, a GPT language model fine-tuned on publicly available code from GitHub, is the model behind GitHub Copilot. [Evaluating Large Language Models Trained on Code](https://arxiv.org/abs/2107.03374) introduced it to the world, while also discussing the potential broader impacts of deploying powerful code generation technologies.

Many developers have found Github Copilot to be quite useful. [Copilot Internals](https://thakkarparth007.github.io/copilot-explorer/posts/copilot-internals.html) looks at its source code and shares how the extension sends valuable information from surrounding code to the Codex model.

When you do or don't hit tab after a GitHub Copilot suggestion, this signals what it should do more or less of in the future. [It’s time to collect data on how you build software](https://blog.continue.dev/its-time-to-collect-data-on-how-you-build-software/) makes you aware of this as you use LLMs when coding.

Software isn’t created in one dramatic step. [Large sequence models for software development activities](https://blog.research.google/2023/05/large-sequence-models-for-software.html) explains how Google is using the process of software development as the source of training data for its ML models that assist developers.

There is a lot of great research on code LLMs. [Awesome-Code-LLM](https://github.com/huybery/Awesome-Code-LLM) is a curated list of best code LLM research and is a great place to read more about the latest.
