# Awesome-DevAI [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

**DevAI is the community of developers building software with the help of [large language models (LLMs)](https://a16z.com/ai-canon).**

## Getting started

Many developers have concerns about how LLMs will impact development. [What AI won’t replace in your programming](https://www.infoworld.com/article/3709230/what-ai-wont-replace-in-your-programming.html) describes why the expertise and intuition of programmers will remain important.

A GitHub survey found that 92% of developers are already using AI tools at work or in their personal time. [Developers are the first group to adopt AI at work. Here’s why that matters.](https://github.blog/2023-10-27-developers-are-the-first-group-to-adopt-ai-at-work-heres-why-that-matters/) provides some insight into how software development is already evolving due to LLMs.

It can be hard to figure out what LLM to use while coding. [What LLM to use? A perspective from the DevAI space](https://github.com/continuedev/what-llm-to-use) walks you through the most popular commercial and open-source models.

Researchers use benchmarks to evaluate and compare the relative performance of LLMs. [An introduction to code LLM benchmarks for software engineers](https://blog.continue.dev/an-introduction-to-code-llm-benchmarks-for-software-engineers/) gives you an overview of the current code benchmarks, so you can use them to figure out which LLMs are worth trying.

When you use an LLM while coding, you might want to adjust the preset. [Is it still necessary to tune an LLM preset? Tracing the history of temperature, penalty, and sampling schemes](https://blog.continue.dev/tune-llm-preset/) gives you the confidence to adjust the model preset when needed.

If you find an open-source code LLM useful, you will likely want to deploy it for your entire team. [How to deploy an open-source code LLM for your dev team](https://github.com/continuedev/deploy-os-code-llm) provides a guide on how to make this happen.

Codex, a GPT language model fine-tuned on publicly available code from GitHub, is the model behind GitHub Copilot. [Evaluating Large Language Models Trained on Code](https://arxiv.org/abs/2107.03374) introduced it to the world, while also discussing the potential broader impacts of deploying powerful code generation technologies.

Many developers have found Github Copilot to be quite useful. [Copilot Internals](https://thakkarparth007.github.io/copilot-explorer/posts/copilot-internals.html) looks at its source code and shares how the extension sends valuable information from surrounding code to the Codex model.

When you do or don't hit tab after a GitHub Copilot suggestion, this signals what it should do more or less of in the future. [It’s time to collect data on how you build software](https://blog.continue.dev/its-time-to-collect-data-on-how-you-build-software/) makes you aware of this as you use LLMs when coding.

Software isn’t created in one dramatic step. [Large sequence models for software development activities](https://blog.research.google/2023/05/large-sequence-models-for-software.html) explains how Google is using the process of software development as the source of training data for its ML models that assist developers.

There is a lot of great research on code LLMs. [Large Language Models for Software Engineering: Survey and Open Problems](https://arxiv.org/abs/2310.03533) gives an overview of the latest as of October 2023.

It's worth it to learn more about code LLM research too. [Awesome-Code-LLM](https://github.com/huybery/Awesome-Code-LLM) is a curated list of best code LLM research and is a great place to read more about the latest.
